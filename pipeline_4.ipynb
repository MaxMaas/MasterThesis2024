{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline 4: Identifying abnormal laboratory results\n",
    "\n",
    "This notebook presents all code used for the evaluation of the code produced for the fourth pipeline, as well as the related relational algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relational algebra\n",
    "$D_{labevents}(labevent\\_id, subject\\_id, hadm\\_id, specimen\\_id, itemid, order\\_provider\\_id, charttime, storetime, value, valuenum, valueuom, ref\\_range\\_lower, ref\\_range\\_upper, flag, priority, comments)$\n",
    "\n",
    "$labevents\\_abnormal = \\sigma_{flag='abnormal'}(labevents)$\n",
    "\n",
    "$labevents\\_abnormal\\_deviate = \\pi_{*, deviation\\_from\\_range(*)}(labevents\\_abnormal)$\n",
    "\n",
    "$labevents\\_abnormal\\_deviate = \\rho_{patient\\_id/subject\\_id}(labevents\\_abnormal\\_deviate)$\n",
    "\n",
    "$final\\_data = \\pi_{labevent\\_id, patient\\_id, hadm\\_id, specimen\\_id, itemid, charttime, storetime, value, valuenum, valueuom, ref\\_range\\_lower, ref\\_range\\_upper, deviation\\_from_range}(abevents\\_abnormal\\_deviate)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports and setup of connection to the database\n",
    "\n",
    "import polars as pl\n",
    "from sqlalchemy import create_engine, inspect, Table, MetaData, Column, Integer, String, DateTime, Float, Boolean\n",
    "import numpy as np\n",
    "\n",
    "engine = create_engine(r\"sqlite://path to where mimic4.db is stored\") #change this to the path where mimic.db is stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth code, used for comparison\n",
    "metadata = MetaData()\n",
    "\n",
    "labevents = Table(\n",
    "    'labevents', metadata,\n",
    "    Column('labevent_id', Integer, nullable=False),\n",
    "    Column('subject_id', Integer, nullable=False),\n",
    "    Column('hadm_id', Integer, primary_key=True),\n",
    "    Column('specimen_id', Integer, nullable=False),\n",
    "    Column('itemid', Integer, primary_key=True, nullable=False),\n",
    "    Column('order_provider_id', String, nullable=True),\n",
    "    Column('charttime', DateTime, nullable=False),\n",
    "    Column('storetime', DateTime, nullable=False),\n",
    "    Column('value', String, nullable=False),\n",
    "    Column('valuenum', Float, nullable=True),\n",
    "    Column('valueuom', String, nullable=False),\n",
    "    Column('ref_range_lower', Float, nullable=False),\n",
    "    Column('ref_range_upper', Float, nullable=False),\n",
    "    Column('flag', String, nullable=False),\n",
    "    Column('priority', String, nullable=True),\n",
    "    Column('comments', String, nullable=True) \n",
    ")\n",
    "\n",
    "metadata.reflect(bind=engine)\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM labevents\n",
    "WHERE flag = 'abnormal'\n",
    "\n",
    "\"\"\"\n",
    "df = pl.read_database(query=query, connection=engine.connect(), infer_schema_length=1000)\n",
    "\n",
    "df.with_columns(pl.col('hadm_id').cast(pl.Int64))\n",
    "\n",
    "# Calculate the deviation of valuenum from the accepted range\n",
    "lower_deviation = df['ref_range_lower'] - df['valuenum']\n",
    "upper_deviation = df['valuenum'] - df['ref_range_upper']\n",
    "\n",
    "# Create a new column with deviations\n",
    "df = df.with_columns(\n",
    "    pl.when(df['valuenum'] < df['ref_range_lower'])\n",
    "    .then(lower_deviation)\n",
    "    .when(df['valuenum'] > df['ref_range_upper'])\n",
    "    .then(upper_deviation)\n",
    "    .otherwise(0)\n",
    "    .alias(\"deviation_from_range\")\n",
    ")\n",
    "\n",
    "df = df.rename({\"subject_id\": \"patient_id\"})\n",
    "\n",
    "df_gt = df.select(['labevent_id', 'patient_id', 'hadm_id', 'specimen_id', 'itemid',\n",
    "                        'charttime', 'storetime', 'value', 'valuenum', 'valueuom', 'ref_range_lower', 'ref_range_upper', 'deviation_from_range'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Valdity \n",
    "\n",
    "In the code block below, the generated code produced by the LLM can be pasted and executed, to assess if the code works without any runtime errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste generated code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Correctness\n",
    "\n",
    "To assess the code correctness, the code below can be executed. If it is correct, True should be returned. Otherwise, manual inspection in the code block below should be executed. It is assumed the presented solution is stored in a variable called 'final data'# Code correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gt.equals(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Execute this code if the dataframes are not equal to see the differences\n",
    "df_combined_pandas = df_combined.to_pandas()\n",
    "final_data_pandas = final_data.to_pandas()\n",
    "\n",
    "df_diff = df_combined_pandas.compare(final_data_pandas)\n",
    "\n",
    "if not df_combined_pandas.equals(final_data_pandas):\n",
    "    print(df_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relative Efficiency\n",
    "\n",
    "To record the average running time for the generated solution, the generated solution can be added to the code block below and executed. The average executrion time should be recorded per solution, for later determination of the relative efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "execution_times = []\n",
    "\n",
    "for i in range(10):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Paste generated code here\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    execution_time = end_time - start_time\n",
    "    execution_times.append(execution_time)\n",
    "\n",
    "\n",
    "average_execution_time = np.mean(execution_times)\n",
    "\n",
    "print(f\"The code executed in average {average_execution_time} seconds over 10 runs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calculate the relative efficiency of the generated solutions\n",
    "def relative_efficiencies(times):\n",
    "    tmin = min(times)\n",
    "    tmax = max(times)\n",
    "    efficiencies = [100 * (1 - (tc - tmin) / (tmax - tmin)) for tc in times]\n",
    "    return efficiencies\n",
    "\n",
    "time_gt = [365.7] # ground truth time\n",
    "solutions = [] # Add the times from the 10 runs here\n",
    "times = time_gt + solutions\n",
    "\n",
    "\n",
    "re = relative_efficiencies(times)\n",
    "# Calculate average\n",
    "average = np.mean(re[1:])\n",
    "print(f'Average: {average}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
